{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM02jXBHgGQDt63UJKKqVIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanusree02/Natural-Language-Processing/blob/main/NLP_LAB_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA WITH ASSIGNMENT EXAMPLE DATA"
      ],
      "metadata": {
        "id": "CBycl2BD_81e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ee5001f",
        "outputId": "a6043135-dfcc-4ace-8dd7-5d505d0d6026"
      },
      "source": [
        "# Install necessary libraries\n",
        "!pip install gensim\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f346560e",
        "outputId": "deba4b67-5f5c-436a-8211-b7715f7ef182"
      },
      "source": [
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "\n",
        "# Download necessary NLTK data (run this once)\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('corpora/omw-1.4')\n",
        "except LookupError:\n",
        "    nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "# Assuming your data is in a DataFrame named 'df' and the text column is 'text_column'\n",
        "# If your DataFrame or text column has a different name, please modify the line below.\n",
        "# For example, if your file is 'data.csv' and the text column is 'description':\n",
        "# df = pd.read_csv('data.csv')\n",
        "# documents = df['description']\n",
        "\n",
        "df = pd.read_csv('/content/data.csv') # Assuming data.csv is your file\n",
        "\n",
        "# Explicitly set the text column to 'text'\n",
        "text_column_name = 'text'\n",
        "\n",
        "# Ensure the column exists and is of string type\n",
        "if text_column_name not in df.columns:\n",
        "    raise ValueError(f\"Column '{text_column_name}' not found in the DataFrame. Please specify the correct text column.\")\n",
        "\n",
        "documents = df[text_column_name].astype(str)\n",
        "\n",
        "print(\"First 5 documents after loading:\")\n",
        "for i, doc in enumerate(documents.head()):\n",
        "    print(f\"{i+1}. {doc}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 documents after loading:\n",
            "1. virat scored century in match\n",
            "2. BJP won in elections\n",
            "3. bumara look 5 wickets in a match\n",
            "4. congress from state government\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43f7b5d3"
      },
      "source": [
        "### Text Preprocessing\n",
        "\n",
        "We need to clean and prepare the text data for LDA. This usually involves:\n",
        "\n",
        "1.  **Lemmatization**: Reducing words to their base form (e.g., 'running' -> 'run').\n",
        "2.  **Tokenization**: Splitting text into individual words.\n",
        "3.  **Stop word removal**: Removing common words that don't add much meaning (e.g., 'the', 'is', 'a').\n",
        "4.  **Short word removal**: Removing words that are too short (e.g., 2 characters or less).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05fee9b0",
        "outputId": "cb21103c-2343-469a-b8d5-71ad6b1030bf"
      },
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) >= 3: # Changed from > 3 to >= 3\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result\n",
        "\n",
        "# Apply preprocessing to your documents\n",
        "processed_docs = documents.apply(preprocess)\n",
        "\n",
        "print(\"First 5 preprocessed documents:\")\n",
        "for i, doc in enumerate(processed_docs.head()):\n",
        "    print(f\"{i+1}. {doc}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 preprocessed documents:\n",
            "1. ['virat', 'score', 'centuri', 'match']\n",
            "2. ['bjp', 'win', 'elect']\n",
            "3. ['bumara', 'look', 'wicket', 'match']\n",
            "4. ['congress', 'state', 'govern']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a74f3e43"
      },
      "source": [
        "### Creating a Dictionary and Corpus\n",
        "\n",
        "Next, we'll create a dictionary mapping each word to an ID and then convert the preprocessed documents into a bag-of-words corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2263fc",
        "outputId": "afff5cf9-d453-4144-b8e4-4bd6c9995d02"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "\n",
        "# Filter out words that appear in less than 15 documents or more than 0.5 fraction of the corpus (minimum number of documents)\n",
        "# This filtering is too aggressive for small datasets, resulting in an empty dictionary.\n",
        "# For this small dataset, we will comment it out to ensure words are not discarded.\n",
        "# dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "\n",
        "# Create the Bag-of-Words corpus\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "print(\"Example of a processed document (bag-of-words representation):\")\n",
        "print(corpus[0])\n",
        "print(\"\\nMapping the first few word IDs to words:\")\n",
        "for i, (word_id, freq) in enumerate(corpus[0]):\n",
        "    if i >= 5: # Print only first 5 for brevity\n",
        "        break\n",
        "    print(f\"Word ID {word_id}: {dictionary[word_id]} (Frequency: {freq})\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of a processed document (bag-of-words representation):\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1)]\n",
            "\n",
            "Mapping the first few word IDs to words:\n",
            "Word ID 0: centuri (Frequency: 1)\n",
            "Word ID 1: match (Frequency: 1)\n",
            "Word ID 2: score (Frequency: 1)\n",
            "Word ID 3: virat (Frequency: 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63d7795b"
      },
      "source": [
        "### Training the LDA Model\n",
        "\n",
        "Now we can train the Latent Dirichlet Allocation (LDA) model using the `gensim` library. You can adjust the number of topics (`num_topics`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ab0ef63",
        "outputId": "c4cfc368-5c29-4b5b-f421-2f0ebb8af89f"
      },
      "source": [
        "# Set the number of topics you want to extract\n",
        "num_topics = 10\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = gensim.models.LdaMulticore(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=num_topics,\n",
        "    random_state=100,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "print(\"LDA model training complete.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efb37aed"
      },
      "source": [
        "### Interpreting the LDA Results\n",
        "\n",
        "Let's print the topics and their associated keywords to understand what each topic represents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "7798daa5",
        "outputId": "6f3e6a8d-ab12-4d63-f689-8306d735b692"
      },
      "source": [
        "print(\"\\nTopics and their keywords:\")\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")\n",
        "\n",
        "# You can also get the dominant topic for each document\n",
        "def format_topics_sentences(ldamodel, corpus, texts):\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row_list in enumerate(ldamodel[corpus]):\n",
        "        row = row_list[0] if ldamodel.per_word_topics else row_list\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = pd.concat([sent_topics_df, pd.DataFrame([{'Dominant_Topic': int(topic_num),\n",
        "                                                         'Perc_Contribution': round(prop_topic,4),\n",
        "                                                         'Topic_Keywords': topic_keywords}])], ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    return sent_topics_df\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=processed_docs)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords']\n",
        "\n",
        "# Add original text to the dataframe\n",
        "df_dominant_topic['Original_Text'] = documents\n",
        "\n",
        "print(\"\\nDominant topic for first 5 documents:\")\n",
        "display(df_dominant_topic.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topics and their keywords:\n",
            "Topic: 0 \n",
            "Words: 0.077*\"match\" + 0.077*\"win\" + 0.077*\"state\" + 0.077*\"elect\" + 0.077*\"govern\" + 0.077*\"congress\" + 0.077*\"score\" + 0.077*\"bumara\" + 0.077*\"bjp\" + 0.077*\"virat\"\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.077*\"govern\" + 0.077*\"match\" + 0.077*\"win\" + 0.077*\"bumara\" + 0.077*\"score\" + 0.077*\"elect\" + 0.077*\"congress\" + 0.077*\"centuri\" + 0.077*\"bjp\" + 0.077*\"wicket\"\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.077*\"match\" + 0.077*\"govern\" + 0.077*\"win\" + 0.077*\"elect\" + 0.077*\"congress\" + 0.077*\"bjp\" + 0.077*\"wicket\" + 0.077*\"score\" + 0.077*\"bumara\" + 0.077*\"virat\"\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.208*\"centuri\" + 0.208*\"match\" + 0.208*\"virat\" + 0.208*\"score\" + 0.019*\"govern\" + 0.019*\"win\" + 0.019*\"bumara\" + 0.019*\"elect\" + 0.019*\"state\" + 0.019*\"congress\"\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.077*\"match\" + 0.077*\"win\" + 0.077*\"state\" + 0.077*\"elect\" + 0.077*\"govern\" + 0.077*\"congress\" + 0.077*\"bumara\" + 0.077*\"bjp\" + 0.077*\"centuri\" + 0.077*\"wicket\"\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.077*\"win\" + 0.077*\"score\" + 0.077*\"elect\" + 0.077*\"match\" + 0.077*\"bumara\" + 0.077*\"congress\" + 0.077*\"govern\" + 0.077*\"state\" + 0.077*\"centuri\" + 0.077*\"virat\"\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.077*\"win\" + 0.077*\"match\" + 0.077*\"elect\" + 0.077*\"govern\" + 0.077*\"congress\" + 0.077*\"state\" + 0.077*\"score\" + 0.077*\"bjp\" + 0.077*\"centuri\" + 0.077*\"bumara\"\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.077*\"match\" + 0.077*\"govern\" + 0.077*\"elect\" + 0.077*\"bjp\" + 0.077*\"state\" + 0.077*\"win\" + 0.077*\"bumara\" + 0.077*\"congress\" + 0.077*\"virat\" + 0.077*\"wicket\"\n",
            "\n",
            "Topic: 8 \n",
            "Words: 0.151*\"bjp\" + 0.151*\"elect\" + 0.151*\"state\" + 0.151*\"congress\" + 0.151*\"win\" + 0.151*\"govern\" + 0.014*\"match\" + 0.014*\"wicket\" + 0.014*\"bumara\" + 0.014*\"centuri\"\n",
            "\n",
            "Topic: 9 \n",
            "Words: 0.208*\"look\" + 0.208*\"match\" + 0.208*\"wicket\" + 0.208*\"bumara\" + 0.019*\"govern\" + 0.019*\"elect\" + 0.019*\"win\" + 0.019*\"score\" + 0.019*\"state\" + 0.019*\"congress\"\n",
            "\n",
            "\n",
            "Dominant topic for first 5 documents:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
              "0            0               3               0.820   \n",
              "1            1               8               0.775   \n",
              "2            2               9               0.820   \n",
              "3            3               8               0.775   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0  centuri, match, virat, score, govern, win, bum...   \n",
              "1  bjp, elect, state, congress, win, govern, matc...   \n",
              "2  look, match, wicket, bumara, govern, elect, wi...   \n",
              "3  bjp, elect, state, congress, win, govern, matc...   \n",
              "\n",
              "                      Original_Text  \n",
              "0     virat scored century in match  \n",
              "1              BJP won in elections  \n",
              "2  bumara look 5 wickets in a match  \n",
              "3    congress from state government  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-754c82bd-8e97-496d-87d7-912b2e9cfab2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_No</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Original_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.820</td>\n",
              "      <td>centuri, match, virat, score, govern, win, bum...</td>\n",
              "      <td>virat scored century in match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.775</td>\n",
              "      <td>bjp, elect, state, congress, win, govern, matc...</td>\n",
              "      <td>BJP won in elections</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.820</td>\n",
              "      <td>look, match, wicket, bumara, govern, elect, wi...</td>\n",
              "      <td>bumara look 5 wickets in a match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0.775</td>\n",
              "      <td>bjp, elect, state, congress, win, govern, matc...</td>\n",
              "      <td>congress from state government</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-754c82bd-8e97-496d-87d7-912b2e9cfab2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-754c82bd-8e97-496d-87d7-912b2e9cfab2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-754c82bd-8e97-496d-87d7-912b2e9cfab2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_dominant_topic\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Document_No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dominant_Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          8,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic_Perc_Contrib\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7749999761581421,\n          0.8199999928474426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"centuri, match, virat, score, govern, win, bumara, elect, state, congress\",\n          \"bjp, elect, state, congress, win, govern, match, wicket, bumara, centuri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"BJP won in elections\",\n          \"congress from state government\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMF FOR LAB ASSIGNMENT WITH SAMPLE DATA SET"
      ],
      "metadata": {
        "id": "XLkFFkVhACYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "950N8qFPAahe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flmnj5BTACC5",
        "outputId": "b6a48748-519c-46c8-9ac7-1558a1194311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CSV (Prepare corpus)"
      ],
      "metadata": {
        "id": "LajiuoBvAcwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "print(df.head())\n",
        "print(\"Columns:\", df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INDmri8YAfWc",
        "outputId": "e211c8c0-fcf4-4f76-b225-e8e13b45604e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                              text\n",
            "0   1     virat scored century in match\n",
            "1   2              BJP won in elections\n",
            "2   3  bumara look 5 wickets in a match\n",
            "3   4    congress from state government\n",
            "Columns: Index(['id', 'text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select text column"
      ],
      "metadata": {
        "id": "2v7MjsIKAs1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = df.columns[0]\n",
        "documents = df[text_col].fillna(\"\").astype(str).tolist()\n",
        "\n",
        "print(documents[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex_H6PY2Auvn",
        "outputId": "ba3ce48e-1e6a-4758-b996-144eaa29593b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text preprocessing"
      ],
      "metadata": {
        "id": "QE6k62ItAwsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(doc):\n",
        "    doc = doc.lower()\n",
        "    doc = re.sub(r'[^a-zA-Z ]', ' ', doc)\n",
        "    tokens = doc.split()\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "clean_docs = [clean_text(doc) for doc in documents]\n",
        "\n",
        "print(clean_docs[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5EOA6isAyQC",
        "outputId": "fe4408d2-5caa-4a25-f891-5e95e7c1b5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce size (fast run)"
      ],
      "metadata": {
        "id": "TMbBcFL2A0mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_docs_small = clean_docs[:5000]\n"
      ],
      "metadata": {
        "id": "gXakhbsVA238"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF matrix (BoW alternative for NMF)"
      ],
      "metadata": {
        "id": "q3Tgpwl1A46_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check documents before TF-IDF\n",
        "print(\"Total docs:\", len(clean_docs_small))\n",
        "\n",
        "# Show first few docs\n",
        "for i, doc in enumerate(clean_docs_small[:5]):\n",
        "    print(i, \"->\", repr(doc))\n",
        "\n",
        "# Remove empty/blank docs safely\n",
        "clean_docs_small = [doc for doc in clean_docs_small if isinstance(doc, str) and doc.strip()]\n",
        "\n",
        "print(\"Docs after cleaning:\", len(clean_docs_small))\n",
        "\n",
        "# If still empty â†’ stop\n",
        "if len(clean_docs_small) == 0:\n",
        "    raise ValueError(\"No valid text found after cleaning!\")\n",
        "\n",
        "# Now run TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(token_pattern=r'(?u)\\b\\w+\\b')  # allow all words\n",
        "X = vectorizer.fit_transform(clean_docs_small)\n",
        "\n",
        "print(\"Matrix shape:\", X.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R306wtl_A4tr",
        "outputId": "58dd9af7-0986-49d3-bfbf-e502814cc2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total docs: 4\n",
            "0 -> 'virat scored century match'\n",
            "1 -> 'bjp election'\n",
            "2 -> 'bumara look wicket match'\n",
            "3 -> 'congress state government'\n",
            "Docs after cleaning: 4\n",
            "Matrix shape: (4, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply NMF + Show Topics"
      ],
      "metadata": {
        "id": "YOmIy9UmCyJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Apply NMF\n",
        "nmf = NMF(n_components=5, random_state=42)\n",
        "W = nmf.fit_transform(X)\n",
        "H = nmf.components_\n",
        "\n",
        "print(\"NMF completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU-lkUojCu6d",
        "outputId": "f9c36dc8-704a-4536-ae7c-cef6f6cb8bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show top words per topic"
      ],
      "metadata": {
        "id": "6_ULXN_CC1Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "for i, topic in enumerate(H):\n",
        "    print(f\"\\nTopic {i+1}:\")\n",
        "    print([words[j] for j in topic.argsort()[-10:]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfPywI3qC29f",
        "outputId": "4f05050e-7f52-41df-edd7-774b82b73838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 1:\n",
            "['century', 'election', 'match', 'look', 'virat', 'scored', 'wicket', 'congress', 'government', 'state']\n",
            "\n",
            "Topic 2:\n",
            "['congress', 'election', 'government', 'scored', 'state', 'virat', 'bumara', 'wicket', 'look', 'match']\n",
            "\n",
            "Topic 3:\n",
            "['congress', 'government', 'look', 'wicket', 'state', 'scored', 'match', 'virat', 'election', 'bjp']\n",
            "\n",
            "Topic 4:\n",
            "['congress', 'election', 'look', 'government', 'wicket', 'state', 'match', 'virat', 'century', 'scored']\n",
            "\n",
            "Topic 5:\n",
            "['congress', 'election', 'government', 'virat', 'state', 'scored', 'match', 'look', 'wicket', 'bumara']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign dominant topic to each document"
      ],
      "metadata": {
        "id": "hw4kIcEbC44H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df.iloc[:len(clean_docs_small)].copy()\n",
        "df_small['Dominant_Topic'] = W.argmax(axis=1)\n",
        "\n",
        "df_small.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "v_OdhQzZC6uO",
        "outputId": "a536ebd7-5c26-4cd9-d8c8-566bf12dbb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "\n",
              "                         terms  Dominant_Topic  \n",
              "0           ['cs.CV', 'cs.LG']               3  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']               2  \n",
              "2           ['cs.CV', 'cs.AI']               4  \n",
              "3                    ['cs.CV']               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c870b2c-9ef0-4a79-b212-c24fb610b864\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c870b2c-9ef0-4a79-b212-c24fb610b864')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c870b2c-9ef0-4a79-b212-c24fb610b864 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c870b2c-9ef0-4a79-b212-c24fb610b864');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_small",
              "summary": "{\n  \"name\": \"df_small\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging\",\n          \"Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation\",\n          \"Survey on Semantic Stereo Matching / Semantic Depth Estimation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"The recent advancements in artificial intelligence (AI) combined with the\\nextensive amount of data generated by today's clinical systems, has led to the\\ndevelopment of imaging AI solutions across the whole value chain of medical\\nimaging, including image reconstruction, medical image segmentation,\\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\\nfuture potential of AI in medical imaging, many stakeholders are concerned of\\nthe potential risks and ethical implications of imaging AI solutions, which are\\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\\nin critical clinical applications. Despite these concerns and risks, there are\\ncurrently no concrete guidelines and best practices for guiding future AI\\ndevelopments in medical imaging towards increased trust, safety and adoption.\\nTo bridge this gap, this paper introduces a careful selection of guiding\\nprinciples drawn from the accumulated experiences, consensus, and best\\npractices from five large European projects on AI in Health Imaging. These\\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\\nand (vi) Explainability. In a step-by-step approach, these guidelines are\\nfurther translated into a framework of concrete recommendations for specifying,\\ndeveloping, evaluating, and deploying technically, clinically and ethically\\ntrustworthy AI solutions into clinical practice.\",\n          \"Consistency training has proven to be an advanced semi-supervised framework\\nand achieved promising results in medical image segmentation tasks through\\nenforcing an invariance of the predictions over different views of the inputs.\\nHowever, with the iterative updating of model parameters, the models would tend\\nto reach a coupled state and eventually lose the ability to exploit unlabeled\\ndata. To address the issue, we present a novel semi-supervised segmentation\\nmodel based on parameter decoupling strategy to encourage consistent\\npredictions from diverse views. Specifically, we first adopt a two-branch\\nnetwork to simultaneously produce predictions for each image. During the\\ntraining process, we decouple the two prediction branch parameters by quadratic\\ncosine distance to construct different views in latent space. Based on this,\\nthe feature extractor is constrained to encourage the consistency of\\nprobability maps generated by classifiers under diversified features. In the\\noverall training process, the parameters of feature extractor and classifiers\\nare updated alternately by consistency regularization operation and decoupling\\noperation to gradually improve the generalization performance of the model. Our\\nmethod has achieved a competitive result over the state-of-the-art\\nsemi-supervised methods on the Atrial Segmentation Challenge dataset,\\ndemonstrating the effectiveness of our framework. Code is available at\\nhttps://github.com/BX0903/PDC.\",\n          \"Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"['cs.CV', 'cs.AI', 'cs.LG']\",\n          \"['cs.CV']\",\n          \"['cs.CV', 'cs.LG']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dominant_Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dce14a4c"
      },
      "source": [
        "LDA FOR LAB ASSIGNMENT WITH KAGGLE DATA SET"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "bo7Qcet-7m1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Step 2: Load CSV file\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\")\n",
        "\n",
        "# IMPORTANT: change column name if needed\n",
        "documents = df.iloc[:,0].astype(str).tolist()   # takes first column as text\n",
        "\n",
        "print(\"Sample documents:\", documents[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjPjdMpV64qS",
        "outputId": "090d9e12-84a0-476b-d6cf-1e51975db3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample documents: ['Survey on Semantic Stereo Matching / Semantic Depth Estimation', 'FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging', 'Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation', 'Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation', 'Background-Foreground Segmentation for Interior Sensing in Automotive Industry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CSV file"
      ],
      "metadata": {
        "id": "O80q75so7n70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/arxiv_data.csv\")\n",
        "\n",
        "print(df.head())\n",
        "print(\"Columns:\", df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXFxLwlQ7Ucs",
        "outputId": "05312939-498c-45bf-acdd-14508d91540d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              titles  \\\n",
            "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
            "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
            "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
            "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
            "4  Background-Foreground Segmentation for Interio...   \n",
            "\n",
            "                                           summaries  \\\n",
            "0  Stereo matching is one of the widely used tech...   \n",
            "1  The recent advancements in artificial intellig...   \n",
            "2  In this paper, we proposed a novel mutual cons...   \n",
            "3  Consistency training has proven to be an advan...   \n",
            "4  To ensure safety in automated driving, the cor...   \n",
            "\n",
            "                         terms  \n",
            "0           ['cs.CV', 'cs.LG']  \n",
            "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
            "2           ['cs.CV', 'cs.AI']  \n",
            "3                    ['cs.CV']  \n",
            "4           ['cs.CV', 'cs.LG']  \n",
            "Columns: Index(['titles', 'summaries', 'terms'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select text column"
      ],
      "metadata": {
        "id": "-i2t9LD97quR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = df.columns[0]\n",
        "documents = df[text_col].fillna(\"\").astype(str).tolist()\n",
        "\n",
        "print(documents[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THaNZ1CX7V9X",
        "outputId": "98c84d65-bf7a-4797-9cb8-874f540eaa37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Survey on Semantic Stereo Matching / Semantic Depth Estimation', 'FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging', 'Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean text"
      ],
      "metadata": {
        "id": "Rh4b3FjE7s7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(doc):\n",
        "    doc = doc.lower()\n",
        "    doc = re.sub(r'[^a-zA-Z ]', ' ', doc)\n",
        "    tokens = doc.split()\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "clean_docs = [clean_text(doc) for doc in documents]\n",
        "\n",
        "print(clean_docs[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuzjFQy_7XtO",
        "outputId": "081c008b-97a7-48c4-d111-8062d5e61a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['survey semantic stereo matching semantic depth estimation', 'future ai guiding principle consensus recommendation trustworthy artificial intelligence future medical imaging', 'enforcing mutual consistency hard region semi supervised medical image segmentation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "TuBI9_jQ7vCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_df=0.9, min_df=5)\n",
        "X = vectorizer.fit_transform(clean_docs)\n",
        "\n",
        "print(\"BoW shape:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ3sjr2k7aye",
        "outputId": "61747101-29da-43f1-b7a1-0b1b3ef08d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW shape: (51774, 4384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply LDA"
      ],
      "metadata": {
        "id": "m1H1eOQ67yAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda.fit(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ay5CcF3m7dVw",
        "outputId": "a9ef4dc0-5c1c-4483-c74d-ec9cdb0b3e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=5, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show topic words"
      ],
      "metadata": {
        "id": "uuZyBfJl7zw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "for i, topic in enumerate(lda.components_):\n",
        "    print(f\"\\nTopic {i+1}:\")\n",
        "    print([words[j] for j in topic.argsort()[-10:]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buyMPQAU7e5Y",
        "outputId": "cf469e8a-2c9f-4ff0-d746-837fd643afec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 1:\n",
            "['segmentation', 'self', 'graph', 'data', 'unsupervised', 'supervised', 'deep', 'representation', 'image', 'learning']\n",
            "\n",
            "Topic 2:\n",
            "['end', 'estimation', 'based', 'temporal', 'image', 'visual', 'transformer', 'recognition', 'attention', 'video']\n",
            "\n",
            "Topic 3:\n",
            "['graph', 'using', 'series', 'deep', 'model', 'time', 'generative', 'neural', 'adversarial', 'network']\n",
            "\n",
            "Topic 4:\n",
            "['optimization', 'super', 'policy', 'via', 'resolution', 'based', 'deep', 'multi', 'reinforcement', 'learning']\n",
            "\n",
            "Topic 5:\n",
            "['based', 'point', 'convolutional', 'graph', 'image', 'neural', 'segmentation', 'object', 'detection', 'network']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign topic to each document"
      ],
      "metadata": {
        "id": "Fnq0srDX72fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_results = lda.transform(X)\n",
        "\n",
        "df['Dominant_Topic'] = topic_results.argmax(axis=1)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NdTgMdJ673bf",
        "outputId": "a7725184-5974-49ae-85c9-014bcfa14101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  Dominant_Topic  \n",
              "0           ['cs.CV', 'cs.LG']               4  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']               0  \n",
              "2           ['cs.CV', 'cs.AI']               0  \n",
              "3                    ['cs.CV']               0  \n",
              "4           ['cs.CV', 'cs.LG']               4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6290e761-35c0-488a-970c-0f9530bf9ad5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6290e761-35c0-488a-970c-0f9530bf9ad5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6290e761-35c0-488a-970c-0f9530bf9ad5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6290e761-35c0-488a-970c-0f9530bf9ad5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 51774,\n  \"fields\": [\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38972,\n        \"samples\": [\n          \"Sum-Product-Transform Networks: Exploiting Symmetries using Invertible Transformations\",\n          \"A Primal-Dual Subgradient Approachfor Fair Meta Learning\",\n          \"Adversarial Multi-Source Transfer Learning in Healthcare: Application to Glucose Prediction for Diabetic People\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38979,\n        \"samples\": [\n          \"Continual learning (CL) is a setting in which an agent has to learn from an\\nincoming stream of data during its entire lifetime. Although major advances\\nhave been made in the field, one recurring problem which remains unsolved is\\nthat of Catastrophic Forgetting (CF). While the issue has been extensively\\nstudied empirically, little attention has been paid from a theoretical angle.\\nIn this paper, we show that the impact of CF increases as two tasks\\nincreasingly align. We introduce a measure of task similarity called the NTK\\noverlap matrix which is at the core of CF. We analyze common projected gradient\\nalgorithms and demonstrate how they mitigate forgetting. Then, we propose a\\nvariant of Orthogonal Gradient Descent (OGD) which leverages structure of the\\ndata through Principal Component Analysis (PCA). Experiments support our\\ntheoretical findings and show how our method can help reduce CF on classical CL\\ndatasets.\",\n          \"Few-shot learning is a challenging task since only few instances are given\\nfor recognizing an unseen class. One way to alleviate this problem is to\\nacquire a strong inductive bias via meta-learning on similar tasks. In this\\npaper, we show that such inductive bias can be learned from a flat collection\\nof unlabeled images, and instantiated as transferable representations among\\nseen and unseen classes. Specifically, we propose a novel part-based\\nself-supervised representation learning scheme to learn transferable\\nrepresentations by maximizing the similarity of an image to its discriminative\\npart. To mitigate the overfitting in few-shot classification caused by data\\nscarcity, we further propose a part augmentation strategy by retrieving extra\\nimages from a base dataset. We conduct systematic studies on miniImageNet and\\ntieredImageNet benchmarks. Remarkably, our method yields impressive results,\\noutperforming the previous best unsupervised methods by 7.74% and 9.24% under\\n5-way 1-shot and 5-way 5-shot settings, which are comparable with\\nstate-of-the-art supervised methods.\",\n          \"Surgical instrument segmentation is extremely important for computer-assisted\\nsurgery. Different from common object segmentation, it is more challenging due\\nto the large illumination and scale variation caused by the special surgical\\nscenes. In this paper, we propose a novel bilinear attention network with\\nadaptive receptive field to solve these two challenges. For the illumination\\nvariation, the bilinear attention module can capture second-order statistics to\\nencode global contexts and semantic dependencies between local pixels. With\\nthem, semantic features in challenging areas can be inferred from their\\nneighbors and the distinction of various semantics can be boosted. For the\\nscale variation, our adaptive receptive field module aggregates multi-scale\\nfeatures and automatically fuses them with different weights. Specifically, it\\nencodes the semantic relationship between channels to emphasize feature maps\\nwith appropriate scales, changing the receptive field of subsequent\\nconvolutions. The proposed network achieves the best performance 97.47% mean\\nIOU on Cata7 and comes first place on EndoVis 2017 by 10.10% IOU overtaking\\nsecond-ranking method.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3157,\n        \"samples\": [\n          \"['cs.LG', 'cs.CE', 'q-fin.ST', 'stat.ML']\",\n          \"['cs.LG', 'physics.comp-ph', 'physics.flu-dyn']\",\n          \"['cs.LG', 'cs.CV', 'math.AT']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dominant_Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMF FOR LAB ASSIGNMENT WITH KAGGLE DATA SET"
      ],
      "metadata": {
        "id": "AhOUCXrj_dRT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c3c39da"
      },
      "source": [
        "# Task\n",
        "Review the NMF topic modeling results from the 'arxiv_data.csv' dataset, including the identified topics and their assigned documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24645370",
        "outputId": "6ab8009f-1c74-447e-e6b8-6b8864d32e6e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_csv(\"/content/arxiv_data.csv\") # Remove this line as df is already loaded\n",
        "\n",
        "# Identify the text column, which is 'titles'\n",
        "text_column_name = 'titles'\n",
        "\n",
        "# Extract the text data, handle missing values, and convert to string type\n",
        "documents = df[text_column_name].fillna(\"\").astype(str).tolist()\n",
        "\n",
        "print(\"First 5 documents after loading and extraction:\")\n",
        "for i, doc in enumerate(documents[:5]):\n",
        "    print(f\"{i+1}. {doc}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 documents after loading and extraction:\n",
            "1. Survey on Semantic Stereo Matching / Semantic Depth Estimation\n",
            "2. FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging\n",
            "3. Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation\n",
            "4. Parameter Decoupling Strategy for Semi-supervised 3D Left Atrium Segmentation\n",
            "5. Background-Foreground Segmentation for Interior Sensing in Automotive Industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cd4ff5"
      },
      "source": [
        "## Preprocess Text Data\n",
        "\n",
        "### Subtask:\n",
        "Clean the text data by converting to lowercase, removing non-alphabetic characters, tokenizing, removing stopwords, and lemmatizing words. This prepares the text for feature extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52243e38",
        "outputId": "f28a21c3-6eb0-4d45-b35a-a23d663193fb"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(doc):\n",
        "    # Convert to lowercase\n",
        "    doc = doc.lower()\n",
        "    # Remove non-alphabetic characters\n",
        "    doc = re.sub(r'[^a-zA-Z ]', ' ', doc)\n",
        "    # Tokenize\n",
        "    tokens = doc.split()\n",
        "    # Lemmatize and remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    # Join tokens back into a string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "clean_docs = [clean_text(doc) for doc in documents]\n",
        "\n",
        "print(\"First 5 cleaned documents:\")\n",
        "for i, doc in enumerate(clean_docs[:5]):\n",
        "    print(f\"{i+1}. {doc}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 cleaned documents:\n",
            "1. survey semantic stereo matching semantic depth estimation\n",
            "2. future ai guiding principle consensus recommendation trustworthy artificial intelligence future medical imaging\n",
            "3. enforcing mutual consistency hard region semi supervised medical image segmentation\n",
            "4. parameter decoupling strategy semi supervised left atrium segmentation\n",
            "5. background foreground segmentation interior sensing automotive industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c152259c",
        "outputId": "1576a697-f9d5-4fd3-c72a-d47905404a2a"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(doc):\n",
        "    # Convert to lowercase\n",
        "    doc = doc.lower()\n",
        "    # Remove non-alphabetic characters\n",
        "    doc = re.sub(r'[^a-zA-Z ]', ' ', doc)\n",
        "    # Tokenize\n",
        "    tokens = doc.split()\n",
        "    # Lemmatize and remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    # Join tokens back into a string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "clean_docs = [clean_text(doc) for doc in documents]\n",
        "\n",
        "print(\"First 5 cleaned documents:\")\n",
        "for i, doc in enumerate(clean_docs[:5]):\n",
        "    print(f\"{i+1}. {doc}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 cleaned documents:\n",
            "1. survey semantic stereo matching semantic depth estimation\n",
            "2. future ai guiding principle consensus recommendation trustworthy artificial intelligence future medical imaging\n",
            "3. enforcing mutual consistency hard region semi supervised medical image segmentation\n",
            "4. parameter decoupling strategy semi supervised left atrium segmentation\n",
            "5. background foreground segmentation interior sensing automotive industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf053f43",
        "outputId": "79764921-999e-4e1f-e4f2-becac6cfeca7"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(doc):\n",
        "    # Convert to lowercase\n",
        "    doc = doc.lower()\n",
        "    # Remove non-alphabetic characters\n",
        "    doc = re.sub(r'[^a-zA-Z ]', ' ', doc)\n",
        "    # Tokenize\n",
        "    tokens = doc.split()\n",
        "    # Lemmatize and remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    # Join tokens back into a string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "clean_docs = [clean_text(doc) for doc in documents]\n",
        "\n",
        "print(\"First 5 cleaned documents:\")\n",
        "for i, doc in enumerate(clean_docs[:5]):\n",
        "    print(f\"{i+1}. {doc}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 cleaned documents:\n",
            "1. survey semantic stereo matching semantic depth estimation\n",
            "2. future ai guiding principle consensus recommendation trustworthy artificial intelligence future medical imaging\n",
            "3. enforcing mutual consistency hard region semi supervised medical image segmentation\n",
            "4. parameter decoupling strategy semi supervised left atrium segmentation\n",
            "5. background foreground segmentation interior sensing automotive industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51baed74"
      },
      "source": [
        "## Create TF-IDF Matrix\n",
        "\n",
        "### Subtask:\n",
        "Transform the preprocessed text data into a TF-IDF (Term Frequency-Inverse Document Frequency) matrix, which is suitable for NMF. This step will convert the text into numerical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a198ee2d",
        "outputId": "553a1275-46b5-4c97-c523-6a7c828c01cb"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the clean_docs to create the TF-IDF matrix\n",
        "X = vectorizer.fit_transform(clean_docs)\n",
        "\n",
        "print(\"TF-IDF matrix shape:\", X.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF matrix shape: (2384, 3136)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bd1250e"
      },
      "source": [
        "## Apply NMF Model\n",
        "\n",
        "### Subtask:\n",
        "Apply Non-negative Matrix Factorization (NMF) to the TF-IDF matrix to discover latent topics within the documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2c11c05",
        "outputId": "a01c1994-6d3d-404f-e253-32e4f8eb32b7"
      },
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Instantiate NMF model with 10 topics and a random state for reproducibility\n",
        "n_components = 10\n",
        "nmf = NMF(n_components=n_components, random_state=42)\n",
        "\n",
        "# Fit the NMF model to the TF-IDF matrix and transform it\n",
        "W = nmf.fit_transform(X) # Document-topic matrix\n",
        "H = nmf.components_ # Topic-word matrix\n",
        "\n",
        "print(f\"NMF model applied with {n_components} topics.\")\n",
        "print(\"Shape of Document-Topic matrix (W):\", W.shape)\n",
        "print(\"Shape of Topic-Word matrix (H):\", H.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF model applied with 10 topics.\n",
            "Shape of Document-Topic matrix (W): (2384, 10)\n",
            "Shape of Topic-Word matrix (H): (10, 3136)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88d76638"
      },
      "source": [
        "## Display Top Words per Topic\n",
        "\n",
        "### Subtask:\n",
        "Extract and display the most representative words for each identified NMF topic to understand the theme of each topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6566870",
        "outputId": "c8ae2af5-a1fe-43ee-d75b-3eabfef3c3e3"
      },
      "source": [
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "for i, topic in enumerate(H):\n",
        "    # Get the indices of the top 10 words for the current topic\n",
        "    top_words_indices = topic.argsort()[-10:]\n",
        "    # Get the actual words using the indices\n",
        "    top_words = [words[j] for j in top_words_indices]\n",
        "    print(f\"\\nTopic {i+1}:\")\n",
        "    print(top_words)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 1:\n",
            "['semi', 'framework', 'active', 'net', 'interactive', 'using', 'based', 'medical', 'segmentation', 'image']\n",
            "\n",
            "Topic 2:\n",
            "['invariant', 'object', 'reinforcement', 'disentangled', 'via', 'video', 'unsupervised', 'visual', 'learning', 'representation']\n",
            "\n",
            "Topic 3:\n",
            "['via', 'attention', 'segmentation', 'using', 'net', 'recurrent', 'fully', 'convolutional', 'neural', 'network']\n",
            "\n",
            "Topic 4:\n",
            "['transformation', 'medical', 'video', 'co', 'training', 'weakly', 'learning', 'semi', 'self', 'supervised']\n",
            "\n",
            "Topic 5:\n",
            "['heterogeneous', 'network', 'via', 'node', 'cut', 'knowledge', 'adaptive', 'embedding', 'based', 'graph']\n",
            "\n",
            "Topic 6:\n",
            "['structured', 'method', 'model', 'based', 'survey', 'detection', 'clustering', 'using', 'learning', 'deep']\n",
            "\n",
            "Topic 7:\n",
            "['fast', 'loss', 'time', 'aware', 'real', 'level', 'video', 'image', 'segmentation', 'semantic']\n",
            "\n",
            "Topic 8:\n",
            "['negative', 'generative', 'representation', 'view', 'medical', 'prototypical', 'global', 'augmentation', 'learning', 'contrastive']\n",
            "\n",
            "Topic 9:\n",
            "['net', 'fusion', 'view', 'level', 'attention', 'label', 'task', 'modal', 'scale', 'multi']\n",
            "\n",
            "Topic 10:\n",
            "['cross', 'person', 'identification', 'adaptive', 'adversarial', 'source', 'generalization', 'unsupervised', 'adaptation', 'domain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1021b8d5"
      },
      "source": [
        "## Assign Dominant Topic to Documents\n",
        "\n",
        "### Subtask:\n",
        "Determine the dominant topic for each document based on the NMF results and add this information back to the original DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "3aa2d8fe",
        "outputId": "75bfed67-b42e-437c-da09-8ed2471e7912"
      },
      "source": [
        "df_topic_distribution = df.copy()\n",
        "df_topic_distribution['Dominant_Topic'] = W.argmax(axis=1)\n",
        "\n",
        "print(\"DataFrame with Dominant Topic assigned:\")\n",
        "df_topic_distribution.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with Dominant Topic assigned:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  Dominant_Topic  \n",
              "0           ['cs.CV', 'cs.LG']               6  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']               0  \n",
              "2           ['cs.CV', 'cs.AI']               3  \n",
              "3                    ['cs.CV']               3  \n",
              "4           ['cs.CV', 'cs.LG']               6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ba3a185-0157-46d2-996a-924c2ec0f2e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ba3a185-0157-46d2-996a-924c2ec0f2e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ba3a185-0157-46d2-996a-924c2ec0f2e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ba3a185-0157-46d2-996a-924c2ec0f2e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_topic_distribution",
              "summary": "{\n  \"name\": \"df_topic_distribution\",\n  \"rows\": 2384,\n  \"fields\": [\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2375,\n        \"samples\": [\n          \"Graph Contrastive Learning with Augmentations\",\n          \"Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation\",\n          \"Multi-Compound Transformer for Accurate Biomedical Image Segmentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2375,\n        \"samples\": [\n          \"Face representation learning solutions have recently achieved great success\\nfor various applications such as verification and identification. However, face\\nrecognition approaches that are based purely on RGB images rely solely on\\nintensity information, and therefore are more sensitive to facial variations,\\nnotably pose, occlusions, and environmental changes such as illumination and\\nbackground. A novel depth-guided attention mechanism is proposed for deep\\nmulti-modal face recognition using low-cost RGB-D sensors. Our novel attention\\nmechanism directs the deep network \\\"where to look\\\" for visual features in the\\nRGB image by focusing the attention of the network using depth features\\nextracted by a Convolution Neural Network (CNN). The depth features help the\\nnetwork focus on regions of the face in the RGB image that contains more\\nprominent person-specific information. Our attention mechanism then uses this\\ncorrelation to generate an attention map for RGB images from the depth features\\nextracted by CNN. We test our network on four public datasets, showing that the\\nfeatures obtained by our proposed solution yield better results on the\\nLock3DFace, CurtinFaces, IIIT-D RGB-D, and KaspAROV datasets which include\\nchallenging variations in pose, occlusion, illumination, expression, and\\ntime-lapse. Our solution achieves average (increased) accuracies of 87.3\\\\%\\n(+5.0\\\\%), 99.1\\\\% (+0.9\\\\%), 99.7\\\\% (+0.6\\\\%) and 95.3\\\\%(+0.5\\\\%) for the four\\ndatasets respectively, thereby improving the state-of-the-art. We also perform\\nadditional experiments with thermal images, instead of depth images, showing\\nthe high generalization ability of our solution when adopting other modalities\\nfor guiding the attention mechanism instead of depth information\",\n          \"Fair representation learning is an attractive approach that promises fairness\\nof downstream predictors by encoding sensitive data. Unfortunately, recent work\\nhas shown that strong adversarial predictors can still exhibit unfairness by\\nrecovering sensitive attributes from these representations. In this work, we\\npresent Fair Normalizing Flows (FNF), a new approach offering more rigorous\\nfairness guarantees for learned representations. Specifically, we consider a\\npractical setting where we can estimate the probability density for sensitive\\ngroups. The key idea is to model the encoder as a normalizing flow trained to\\nminimize the statistical distance between the latent representations of\\ndifferent groups. The main advantage of FNF is that its exact likelihood\\ncomputation allows us to obtain guarantees on the maximum unfairness of any\\npotentially adversarial downstream predictor. We experimentally demonstrate the\\neffectiveness of FNF in enforcing various group fairness notions, as well as\\nother attractive properties such as interpretability and transfer learning, on\\na variety of challenging real-world datasets.\",\n          \"The recent vision transformer(i.e.for image classification) learns non-local\\nattentive interaction of different patch tokens. However, prior arts miss\\nlearning the cross-scale dependencies of different pixels, the semantic\\ncorrespondence of different labels, and the consistency of the feature\\nrepresentations and semantic embeddings, which are critical for biomedical\\nsegmentation. In this paper, we tackle the above issues by proposing a unified\\ntransformer network, termed Multi-Compound Transformer (MCTrans), which\\nincorporates rich feature learning and semantic structure mining into a unified\\nframework. Specifically, MCTrans embeds the multi-scale convolutional features\\nas a sequence of tokens and performs intra- and inter-scale self-attention,\\nrather than single-scale attention in previous works. In addition, a learnable\\nproxy embedding is also introduced to model semantic relationship and feature\\nenhancement by using self-attention and cross-attention, respectively. MCTrans\\ncan be easily plugged into a UNet-like network and attains a significant\\nimprovement over the state-of-the-art methods in biomedical image segmentation\\nin six standard benchmarks. For example, MCTrans outperforms UNet by 3.64%,\\n3.71%, 4.34%, 2.8%, 1.88%, 1.57% in Pannuke, CVC-Clinic, CVC-Colon, Etis,\\nKavirs, ISIC2018 dataset, respectively. Code is available at\\nhttps://github.com/JiYuanFeng/MCTrans.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 332,\n        \"samples\": [\n          \"['cs.LG', 'cs.CR', 'cs.NE', 'stat.ML']\",\n          \"['cs.LG', 'cs.DB', 'stat.ML']\",\n          \"['cs.CV', '62H30', 'I.4.6']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dominant_Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}