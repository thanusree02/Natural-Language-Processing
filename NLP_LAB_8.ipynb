{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIt/xBPGX9YkKCt/6g1FMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanusree02/Natural-Language-Processing/blob/main/NLP_LAB_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libraries"
      ],
      "metadata": {
        "id": "HX0phyRxH-sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2 — Import Required Libraries\n",
        "\n",
        "# re → used for text cleaning (remove punctuation & numbers)\n",
        "import re\n",
        "\n",
        "# collections → helps count words and n-grams easily\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# math → used for probability & perplexity calculations\n",
        "import math\n",
        "\n",
        "# nltk → tokenization and stopword removal\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required nltk data (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBmvpqilGdbT",
        "outputId": "7d5b424f-81cc-48d3-9fb9-e8c2ca064a4b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "zlN-v0hFH7wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3 — Load Dataset\n",
        "\n",
        "documents = [\n",
        "    \"Artificial intelligence is transforming healthcare and education.\",\n",
        "    \"Machine learning models learn patterns from large datasets.\",\n",
        "    \"Deep learning improves image recognition and speech processing.\",\n",
        "    \"Ethical AI ensures fairness, transparency, and accountability.\"\n",
        "]\n",
        "\n",
        "print(\"Sample dataset:\")\n",
        "for doc in documents:\n",
        "    print(\"-\", doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaaOn3fYGzXe",
        "outputId": "8e95ae87-2f7d-45b1-9c83-31e7a9f3fccf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset:\n",
            "- Artificial intelligence is transforming healthcare and education.\n",
            "- Machine learning models learn patterns from large datasets.\n",
            "- Deep learning improves image recognition and speech processing.\n",
            "- Ethical AI ensures fairness, transparency, and accountability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Text"
      ],
      "metadata": {
        "id": "CD32NHMgH5ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4 — Preprocess Text\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(sentence):\n",
        "    # Convert to lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Remove punctuation and numbers\n",
        "    sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    # Remove stopwords (optional)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Add start/end tokens\n",
        "    tokens = ['<s>'] + tokens + ['</s>']\n",
        "\n",
        "    return tokens\n",
        "\n",
        "processed_docs = [preprocess(doc) for doc in documents]\n",
        "\n",
        "print(\"Processed sentences:\")\n",
        "for sent in processed_docs:\n",
        "    print(sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDSXneqzG3mF",
        "outputId": "f1baf2a6-b5c8-451f-846c-a7aa2eeb7696"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed sentences:\n",
            "['<s>', 'artificial', 'intelligence', 'transforming', 'healthcare', 'education', '</s>']\n",
            "['<s>', 'machine', 'learning', 'models', 'learn', 'patterns', 'large', 'datasets', '</s>']\n",
            "['<s>', 'deep', 'learning', 'improves', 'image', 'recognition', 'speech', 'processing', '</s>']\n",
            "['<s>', 'ethical', 'ai', 'ensures', 'fairness', 'transparency', 'accountability', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram"
      ],
      "metadata": {
        "id": "mKpcGOTIH3CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram\n",
        "unigram_counts = Counter()\n",
        "\n",
        "for sent in processed_docs:\n",
        "    unigram_counts.update(sent)\n",
        "\n",
        "total_unigrams = sum(unigram_counts.values())\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "print(unigram_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHgrdRwlG44l",
        "outputId": "d4e51a61-2289-467e-f6be-4ba968ac3bdb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "Counter({'<s>': 4, '</s>': 4, 'learning': 2, 'artificial': 1, 'intelligence': 1, 'transforming': 1, 'healthcare': 1, 'education': 1, 'machine': 1, 'models': 1, 'learn': 1, 'patterns': 1, 'large': 1, 'datasets': 1, 'deep': 1, 'improves': 1, 'image': 1, 'recognition': 1, 'speech': 1, 'processing': 1, 'ethical': 1, 'ai': 1, 'ensures': 1, 'fairness': 1, 'transparency': 1, 'accountability': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram"
      ],
      "metadata": {
        "id": "22EzSB3ZHzF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigram\n",
        "bigram_counts = Counter()\n",
        "\n",
        "for sent in processed_docs:\n",
        "    for i in range(len(sent)-1):\n",
        "        bigram = (sent[i], sent[i+1])\n",
        "        bigram_counts[bigram] += 1\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "print(bigram_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS3m9CtmG7NA",
        "outputId": "2d4ec9ba-4ffd-4f76-e31b-ebf13b5ba357"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "Counter({('<s>', 'artificial'): 1, ('artificial', 'intelligence'): 1, ('intelligence', 'transforming'): 1, ('transforming', 'healthcare'): 1, ('healthcare', 'education'): 1, ('education', '</s>'): 1, ('<s>', 'machine'): 1, ('machine', 'learning'): 1, ('learning', 'models'): 1, ('models', 'learn'): 1, ('learn', 'patterns'): 1, ('patterns', 'large'): 1, ('large', 'datasets'): 1, ('datasets', '</s>'): 1, ('<s>', 'deep'): 1, ('deep', 'learning'): 1, ('learning', 'improves'): 1, ('improves', 'image'): 1, ('image', 'recognition'): 1, ('recognition', 'speech'): 1, ('speech', 'processing'): 1, ('processing', '</s>'): 1, ('<s>', 'ethical'): 1, ('ethical', 'ai'): 1, ('ai', 'ensures'): 1, ('ensures', 'fairness'): 1, ('fairness', 'transparency'): 1, ('transparency', 'accountability'): 1, ('accountability', '</s>'): 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trigram"
      ],
      "metadata": {
        "id": "rYZF-OGJHyCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigram\n",
        "trigram_counts = Counter()\n",
        "\n",
        "for sent in processed_docs:\n",
        "    for i in range(len(sent)-2):\n",
        "        trigram = (sent[i], sent[i+1], sent[i+2])\n",
        "        trigram_counts[trigram] += 1\n",
        "\n",
        "print(\"\\nTrigram Counts:\")\n",
        "print(trigram_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0hlQqVFG_GK",
        "outputId": "0c3b54c0-648c-4839-ad41-d2fde482abd4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigram Counts:\n",
            "Counter({('<s>', 'artificial', 'intelligence'): 1, ('artificial', 'intelligence', 'transforming'): 1, ('intelligence', 'transforming', 'healthcare'): 1, ('transforming', 'healthcare', 'education'): 1, ('healthcare', 'education', '</s>'): 1, ('<s>', 'machine', 'learning'): 1, ('machine', 'learning', 'models'): 1, ('learning', 'models', 'learn'): 1, ('models', 'learn', 'patterns'): 1, ('learn', 'patterns', 'large'): 1, ('patterns', 'large', 'datasets'): 1, ('large', 'datasets', '</s>'): 1, ('<s>', 'deep', 'learning'): 1, ('deep', 'learning', 'improves'): 1, ('learning', 'improves', 'image'): 1, ('improves', 'image', 'recognition'): 1, ('image', 'recognition', 'speech'): 1, ('recognition', 'speech', 'processing'): 1, ('speech', 'processing', '</s>'): 1, ('<s>', 'ethical', 'ai'): 1, ('ethical', 'ai', 'ensures'): 1, ('ai', 'ensures', 'fairness'): 1, ('ensures', 'fairness', 'transparency'): 1, ('fairness', 'transparency', 'accountability'): 1, ('transparency', 'accountability', '</s>'): 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conditional Probabilities"
      ],
      "metadata": {
        "id": "3NDRPL91Hvxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigram probabilities\n",
        "bigram_probs = {}\n",
        "\n",
        "for (w1, w2), count in bigram_counts.items():\n",
        "    bigram_probs[(w1, w2)] = count / unigram_counts[w1]\n",
        "\n",
        "print(\"\\nBigram Probabilities:\")\n",
        "print(bigram_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY2wSgyCHBzg",
        "outputId": "b7309b2f-2727-449f-f224-e20a2085517d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Probabilities:\n",
            "{('<s>', 'artificial'): 0.25, ('artificial', 'intelligence'): 1.0, ('intelligence', 'transforming'): 1.0, ('transforming', 'healthcare'): 1.0, ('healthcare', 'education'): 1.0, ('education', '</s>'): 1.0, ('<s>', 'machine'): 0.25, ('machine', 'learning'): 1.0, ('learning', 'models'): 0.5, ('models', 'learn'): 1.0, ('learn', 'patterns'): 1.0, ('patterns', 'large'): 1.0, ('large', 'datasets'): 1.0, ('datasets', '</s>'): 1.0, ('<s>', 'deep'): 0.25, ('deep', 'learning'): 1.0, ('learning', 'improves'): 0.5, ('improves', 'image'): 1.0, ('image', 'recognition'): 1.0, ('recognition', 'speech'): 1.0, ('speech', 'processing'): 1.0, ('processing', '</s>'): 1.0, ('<s>', 'ethical'): 0.25, ('ethical', 'ai'): 1.0, ('ai', 'ensures'): 1.0, ('ensures', 'fairness'): 1.0, ('fairness', 'transparency'): 1.0, ('transparency', 'accountability'): 1.0, ('accountability', '</s>'): 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigram probabilities\n",
        "trigram_probs = {}\n",
        "\n",
        "for (w1, w2, w3), count in trigram_counts.items():\n",
        "    trigram_probs[(w1, w2, w3)] = count / bigram_counts[(w1, w2)]\n",
        "\n",
        "print(\"\\nTrigram Probabilities:\")\n",
        "print(trigram_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7-GhRdqHDAR",
        "outputId": "fb2746a0-bda8-43e0-8f87-5b174d92562b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigram Probabilities:\n",
            "{('<s>', 'artificial', 'intelligence'): 1.0, ('artificial', 'intelligence', 'transforming'): 1.0, ('intelligence', 'transforming', 'healthcare'): 1.0, ('transforming', 'healthcare', 'education'): 1.0, ('healthcare', 'education', '</s>'): 1.0, ('<s>', 'machine', 'learning'): 1.0, ('machine', 'learning', 'models'): 1.0, ('learning', 'models', 'learn'): 1.0, ('models', 'learn', 'patterns'): 1.0, ('learn', 'patterns', 'large'): 1.0, ('patterns', 'large', 'datasets'): 1.0, ('large', 'datasets', '</s>'): 1.0, ('<s>', 'deep', 'learning'): 1.0, ('deep', 'learning', 'improves'): 1.0, ('learning', 'improves', 'image'): 1.0, ('improves', 'image', 'recognition'): 1.0, ('image', 'recognition', 'speech'): 1.0, ('recognition', 'speech', 'processing'): 1.0, ('speech', 'processing', '</s>'): 1.0, ('<s>', 'ethical', 'ai'): 1.0, ('ethical', 'ai', 'ensures'): 1.0, ('ai', 'ensures', 'fairness'): 1.0, ('ensures', 'fairness', 'transparency'): 1.0, ('fairness', 'transparency', 'accountability'): 1.0, ('transparency', 'accountability', '</s>'): 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add-One (Laplace) Smoothing"
      ],
      "metadata": {
        "id": "44y9-CTFHjgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(unigram_counts)\n",
        "\n",
        "def laplace_bigram_prob(w1, w2):\n",
        "    return (bigram_counts[(w1, w2)] + 1) / (unigram_counts[w1] + vocab_size)\n"
      ],
      "metadata": {
        "id": "uZQyCWkzHFsA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Probability"
      ],
      "metadata": {
        "id": "jztmA_cTHhJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"AI improves healthcare\",\n",
        "    \"machine learning models\",\n",
        "    \"ethical AI ensures fairness\",\n",
        "    \"deep learning improves speech\",\n",
        "    \"AI models learn patterns\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "pxgirVCZHIL4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram Probability"
      ],
      "metadata": {
        "id": "MyaTRf6dHfo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_prob(sentence):\n",
        "    tokens = preprocess(sentence)\n",
        "    prob = 1\n",
        "    for word in tokens:\n",
        "        prob *= (unigram_counts[word] + 1) / (total_unigrams + vocab_size)\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "hsa0a5BKHLMv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram Probability"
      ],
      "metadata": {
        "id": "9yS5oue7Hd5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_prob(sentence):\n",
        "    tokens = preprocess(sentence)\n",
        "    prob = 1\n",
        "    for i in range(len(tokens)-1):\n",
        "        prob *= laplace_bigram_prob(tokens[i], tokens[i+1])\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "f6uD-HobHMvL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trigram Probability"
      ],
      "metadata": {
        "id": "6bOvJfWsHb9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trigram_prob(sentence):\n",
        "    tokens = preprocess(sentence)\n",
        "    prob = 1\n",
        "    for i in range(len(tokens)-2):\n",
        "        count = trigram_counts[(tokens[i], tokens[i+1], tokens[i+2])] + 1\n",
        "        base = bigram_counts[(tokens[i], tokens[i+1])] + vocab_size\n",
        "        prob *= count / base\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "e_mj2OvDHOXy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in test_sentences:\n",
        "    print(\"\\nSentence:\", s)\n",
        "    print(\"Unigram:\", unigram_prob(s))\n",
        "    print(\"Bigram:\", bigram_prob(s))\n",
        "    print(\"Trigram:\", trigram_prob(s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEYxdb0DHQAJ",
        "outputId": "f3efaf05-f988-43ca-b11b-88e07ff4da2c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: AI improves healthcare\n",
            "Unigram: 2.797498983874935e-07\n",
            "Bigram: 1.6935087808430286e-06\n",
            "Trigram: 5.689576695493856e-05\n",
            "\n",
            "Sentence: machine learning models\n",
            "Unigram: 4.1962484758124015e-07\n",
            "Bigram: 1.3064210595074791e-05\n",
            "Trigram: 0.00020322105370116343\n",
            "\n",
            "Sentence: ethical AI ensures fairness\n",
            "Unigram: 9.48304740296588e-09\n",
            "Bigram: 1.003560759018091e-06\n",
            "Trigram: 1.5053411385271365e-05\n",
            "\n",
            "Sentence: deep learning improves speech\n",
            "Unigram: 1.422457110444882e-08\n",
            "Bigram: 4.838596516694367e-07\n",
            "Trigram: 7.81619437312167e-06\n",
            "\n",
            "Sentence: AI models learn patterns\n",
            "Unigram: 9.48304740296588e-09\n",
            "Bigram: 2.5089018975452275e-07\n",
            "Trigram: 4.058408616813175e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity Calculation"
      ],
      "metadata": {
        "id": "L78kQKJtHX3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, model=\"bigram\"):\n",
        "    tokens = preprocess(sentence)\n",
        "    N = len(tokens)\n",
        "\n",
        "    if model == \"unigram\":\n",
        "        prob = unigram_prob(sentence)\n",
        "    elif model == \"bigram\":\n",
        "        prob = bigram_prob(sentence)\n",
        "    else:\n",
        "        prob = trigram_prob(sentence)\n",
        "\n",
        "    return pow(1/prob, 1/N)\n"
      ],
      "metadata": {
        "id": "54GOB5laHSHI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in test_sentences:\n",
        "    print(\"\\nSentence:\", s)\n",
        "    print(\"Unigram Perplexity:\", perplexity(s, \"unigram\"))\n",
        "    print(\"Bigram Perplexity:\", perplexity(s, \"bigram\"))\n",
        "    print(\"Trigram Perplexity:\", perplexity(s, \"trigram\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7YfcTy_HUSP",
        "outputId": "06e41fec-cb3e-46c1-8f64-45f221fdafa1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: AI improves healthcare\n",
            "Unigram Perplexity: 20.447772873076822\n",
            "Bigram Perplexity: 14.264038732150023\n",
            "Trigram Perplexity: 7.062915473248846\n",
            "\n",
            "Sentence: machine learning models\n",
            "Unigram Perplexity: 18.855053138445598\n",
            "Bigram Perplexity: 9.479454917247816\n",
            "Trigram Perplexity: 5.475279077038852\n",
            "\n",
            "Sentence: ethical AI ensures fairness\n",
            "Unigram Perplexity: 21.735785841978277\n",
            "Bigram Perplexity: 9.994077696835463\n",
            "Trigram Perplexity: 6.363961030678927\n",
            "\n",
            "Sentence: deep learning improves speech\n",
            "Unigram Perplexity: 20.3154666801183\n",
            "Bigram Perplexity: 11.286174616252682\n",
            "Trigram Perplexity: 7.098513972447532\n",
            "\n",
            "Sentence: AI models learn patterns\n",
            "Unigram Perplexity: 21.735785841978277\n",
            "Bigram Perplexity: 12.59174886452787\n",
            "Trigram Perplexity: 7.917851849519763\n"
          ]
        }
      ]
    }
  ]
}